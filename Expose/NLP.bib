
@inproceedings{nunamaker_systems_1990,
	title = {Systems development in information systems research},
	volume = {3},
	doi = {10.1109/HICSS.1990.205401},
	abstract = {The authors critically review systems development in information systems (IS) research. Several classification schemes of research are described and systems development is identified as a developmental, engineering, and formulative type of research. A framework of research is proposed to explain the dual nature of systems development as a research methodology and a research domain in IS research. Progress in several disciplinary areas is reviewed to provide a basis to argue that systems development is a valid research methodology. A systems development research process is presented from a methodological perspective. Software engineering, the basic method is applying the systems development research methodology, is then discussed. A framework to classify IS research domain and various research methodologies in studying systems development is presented. It is suggested that systems development and empirical research methodologies are complementary to each other. It is further proposed that an integrated multidimensional and multimethodological approach will generate fruitful research results in IS research.{\textless}{\textgreater}},
	booktitle = {Twenty-{Third} {Annual} {Hawaii} {International} {Conference} on {System} {Sciences}},
	author = {Nunamaker, J.F. and Chen, M.},
	month = jan,
	year = {1990},
	keywords = {Humans, Testing, Design engineering, Design methodology, Information systems, Management information systems, Production systems, Prototypes, Research and development, Software engineering},
	pages = {631--640 vol.3},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Anne\\Zotero\\storage\\EILMBHNV\\205401.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Anne\\Zotero\\storage\\44DUT8S7\\Nunamaker und Chen - 1990 - Systems development in information systems researc.pdf:application/pdf},
}

@article{polson_cognitive_1992,
	title = {Cognitive walkthroughs: a method for theory-based evaluation of user interfaces},
	volume = {36},
	issn = {00207373},
	shorttitle = {Cognitive walkthroughs},
	url = {https://linkinghub.elsevier.com/retrieve/pii/002073739290039N},
	doi = {10.1016/0020-7373(92)90039-N},
	language = {en},
	number = {5},
	urldate = {2022-10-05},
	journal = {International Journal of Man-Machine Studies},
	author = {Polson, Peter G. and Lewis, Clayton and Rieman, John and Wharton, Cathleen},
	month = may,
	year = {1992},
	pages = {741--773},
	file = {Polson et al. - 1992 - Cognitive walkthroughs a method for theory-based .pdf:C\:\\Users\\Anne\\Zotero\\storage\\K7CYFLRF\\Polson et al. - 1992 - Cognitive walkthroughs a method for theory-based .pdf:application/pdf},
}

@incollection{simari_argument_2009,
	address = {Boston, MA},
	title = {The {Argument} {Interchange} {Format}},
	isbn = {978-0-387-98196-3 978-0-387-98197-0},
	url = {http://link.springer.com/10.1007/978-0-387-98197-0_19},
	language = {en},
	urldate = {2022-10-07},
	booktitle = {Argumentation in {Artificial} {Intelligence}},
	publisher = {Springer US},
	author = {Rahwan, Iyad and Reed, Chris},
	editor = {Simari, Guillermo and Rahwan, Iyad},
	year = {2009},
	doi = {10.1007/978-0-387-98197-0_19},
	pages = {383--402},
	file = {Rahwan und Reed - 2009 - The Argument Interchange Format.pdf:C\:\\Users\\Anne\\Zotero\\storage\\24274X7B\\Rahwan und Reed - 2009 - The Argument Interchange Format.pdf:application/pdf},
}

@misc{noauthor_argument_2022,
	title = {Argument technology},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Argument_technology&oldid=1064858420},
	abstract = {Argument technology is a sub-field of artificial intelligence that focuses on applying computational techniques to the creation, identification, analysis, navigation, evaluation and visualisation of arguments and debates. In the 1980s and 1990s, philosophical theories of arguments in general, and argumentation theory in particular, were leveraged to handle key computational challenges, such as modeling non-monotonic and defeasible reasoning and designing robust coordination protocols for multi-agent systems. At the same time, mechanisms for computing semantics of Argumentation frameworks were introduced as a way of providing a calculus of opposition for computing what it is reasonable to believe in the context of conflicting arguments.With these foundations in place, the area was kick-started by a workshop held in the Scottish Highlands in 2000, the result of which was a book coauthored by philosophers of argument, rhetoricians, legal scholars and AI researchers. Since then, the area has been supported by various dedicated events such as the International Workshop on Computational Models of Natural Argument (CMNA) which has run annually since 2001; the International Workshop on Argument in Multi Agent Systems (ArgMAS) annually since 2004; the Workshop on Argument Mining, annually since 2014, and the Conference on Computational Models of Argument (COMMA), biennially since 2006. Since 2010, the field has also had its own journal, Argument \& Computation, which was published by Taylor \& Francis until 2016 and since then by IOS Press.One of the challenges that argument technology faced was a lack of standardisation in the representation and underlying conception of argument in machine readable terms. Many different software tools for manual argument analysis, in particular, developed idiosyncratic and ad hoc ways of representing arguments which reflected differing underlying ways of conceiving of argumentative structure. This lack of standardisation also meant that there was no interchange between tools or between research projects, and little re-use of data resources that were often expensive to create. To tackle this problem, the Argument Interchange Format set out to establish a common standard that captured the minimal common features of argumentation which could then be extended in different settings.
Since about 2018, argument technology has been growing rapidly, with, for example, IBM's Grand Challenge, Project Debater, results for which were published in Nature in March 2021; German research funder, DFG's nationwide research programme on Robust Argumentation Machines, RATIO, begun in 2019; and UK nationwide deployment of The Evidence Toolkit by the BBC in 2019. A 2021 video narrated by Stephen Fry provides a summary of the societal motivations for work in argument technology.Argument technology has applications in a variety of domains, including education, healthcare, policy making, political science, intelligence analysis and risk management and has a variety of sub-fields, methodologies and technologies.},
	language = {en},
	urldate = {2022-10-07},
	journal = {Wikipedia},
	month = jan,
	year = {2022},
	note = {Page Version ID: 1064858420},
	file = {Snapshot:C\:\\Users\\Anne\\Zotero\\storage\\PGR2WPUL\\Argument_technology.html:text/html},
}

@article{bex_logical_nodate,
	title = {On {Logical} {Reiﬁcations} of the {Argument} {Interchange} {Format}},
	abstract = {The Argument Interchange Format (AIF) has been devised in order to support the interchange of ideas and data between different projects and applications in the area of computational argumentation. The AIF presents an abstract ontology for argumentation which serves as an interlingua between various reiﬁcations that consist of more concrete argumentation languages. In this paper, we aim to give a logical reiﬁcation of the AIF ontology, by deﬁning translations between the ontology’s language and the formal ASPIC+ framework for argumentation. We thus lay foundations for interrelating formal logic-based approaches to argumentation captured by the general ASPIC+ framework, and the wider class of AIF reiﬁcations, including those that are more informal and user orientated.},
	language = {en},
	author = {Bex, Floris and Modgil, Sanjay and Prakken, Henry and Reed, Chris},
	pages = {37},
	file = {Bex et al. - On Logical Reiﬁcations of the Argument Interchange.pdf:C\:\\Users\\Anne\\Zotero\\storage\\HZVMJHQT\\Bex et al. - On Logical Reiﬁcations of the Argument Interchange.pdf:application/pdf},
}

@article{thimm_verteilte_nodate,
	title = {Verteilte logikbasierte {Argumentation} unter {Berücksichtigung} unsicheren {Wissens} mit {Anwendung} auf ein {Beispiel} aus dem {Rechtswesen}},
	language = {de},
	author = {Thimm, Matthias},
	pages = {124},
	file = {Thimm - Verteilte logikbasierte Argumentation unter Berück.pdf:C\:\\Users\\Anne\\Zotero\\storage\\UWC2ZETX\\Thimm - Verteilte logikbasierte Argumentation unter Berück.pdf:application/pdf},
}

@article{nawroth_supporting_nodate,
	title = {Supporting {Information} {Retrieval} of {Emerging} {Knowledge} and {Argumentation}},
	language = {de},
	author = {Nawroth, Christian},
	pages = {445},
	file = {Nawroth - Supporting Information Retrieval of Emerging Knowl.pdf:C\:\\Users\\Anne\\Zotero\\storage\\5ZPD5J22\\Nawroth - Supporting Information Retrieval of Emerging Knowl.pdf:application/pdf},
}

@misc{noauthor_sensor_nodate,
	title = {Sensor {Enabled} {Affective} {Computing} for {Enhancing} {Medical} {Care} {\textbar} {SenseCare} {Project} {\textbar} {Fact} {Sheet} {\textbar} {H2020} {\textbar} {CORDIS} {\textbar} {European} {Commission}},
	url = {https://cordis.europa.eu/project/id/690862},
	urldate = {2022-10-17},
	file = {Sensor Enabled Affective Computing for Enhancing Medical Care | SenseCare Project | Fact Sheet | H2020 | CORDIS | European Commission:C\:\\Users\\Anne\\Zotero\\storage\\H9Z4QL42\\690862.html:text/html},
}

@misc{shen_entity_2021,
	title = {Entity {Linking} {Meets} {Deep} {Learning}: {Techniques} and {Solutions}},
	shorttitle = {Entity {Linking} {Meets} {Deep} {Learning}},
	url = {http://arxiv.org/abs/2109.12520},
	abstract = {Entity linking (EL) is the process of linking entity mentions appearing in web text with their corresponding entities in a knowledge base. EL plays an important role in the ﬁelds of knowledge engineering and data mining, underlying a variety of downstream applications such as knowledge base population, content analysis, relation extraction, and question answering. In recent years, deep learning (DL), which has achieved tremendous success in various domains, has also been leveraged in EL methods to surpass traditional machine learning based methods and yield the state-of-the-art performance. In this survey, we present a comprehensive review and analysis of existing DL based EL methods. First of all, we propose a new taxonomy, which organizes existing DL based EL methods using three axes: embedding, feature, and algorithm. Then we systematically survey the representative EL methods along the three axes of the taxonomy. Later, we introduce ten commonly used EL data sets and give a quantitative performance analysis of DL based EL methods over these data sets. Finally, we discuss the remaining limitations of existing methods and highlight some promising future directions.},
	language = {en},
	urldate = {2022-10-17},
	publisher = {arXiv},
	author = {Shen, Wei and Li, Yuhan and Liu, Yinan and Han, Jiawei and Wang, Jianyong and Yuan, Xiaojie},
	month = sep,
	year = {2021},
	note = {arXiv:2109.12520 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
	annote = {Comment: To appear in IEEE TKDE},
	file = {Shen et al. - 2021 - Entity Linking Meets Deep Learning Techniques and.pdf:C\:\\Users\\Anne\\Zotero\\storage\\6MPHWRBH\\Shen et al. - 2021 - Entity Linking Meets Deep Learning Techniques and.pdf:application/pdf},
}

@incollection{hutchison_dbpedia_2007,
	address = {Berlin, Heidelberg},
	title = {{DBpedia}: {A} {Nucleus} for a {Web} of {Open} {Data}},
	volume = {4825},
	isbn = {978-3-540-76297-3 978-3-540-76298-0},
	shorttitle = {{DBpedia}},
	url = {http://link.springer.com/10.1007/978-3-540-76298-0_52},
	abstract = {DBpedia is a community eﬀort to extract structured information from Wikipedia and to make this information available on the Web. DBpedia allows you to ask sophisticated queries against datasets derived from Wikipedia and to link other datasets on the Web to Wikipedia data. We describe the extraction of the DBpedia datasets, and how the resulting information is published on the Web for human- and machine-consumption. We describe some emerging applications from the DBpedia community and show how website authors can facilitate DBpedia content within their sites. Finally, we present the current status of interlinking DBpedia with other open datasets on the Web and outline how DBpedia could serve as a nucleus for an emerging Web of open data.},
	language = {en},
	urldate = {2022-10-18},
	booktitle = {The {Semantic} {Web}},
	publisher = {Springer Berlin Heidelberg},
	author = {Auer, Sören and Bizer, Christian and Kobilarov, Georgi and Lehmann, Jens and Cyganiak, Richard and Ives, Zachary},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Aberer, Karl and Choi, Key-Sun and Noy, Natasha and Allemang, Dean and Lee, Kyung-Il and Nixon, Lyndon and Golbeck, Jennifer and Mika, Peter and Maynard, Diana and Mizoguchi, Riichiro and Schreiber, Guus and Cudré-Mauroux, Philippe},
	year = {2007},
	doi = {10.1007/978-3-540-76298-0_52},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {722--735},
	file = {Auer et al. - 2007 - DBpedia A Nucleus for a Web of Open Data.pdf:C\:\\Users\\Anne\\Zotero\\storage\\QSZ45SJ6\\Auer et al. - 2007 - DBpedia A Nucleus for a Web of Open Data.pdf:application/pdf},
}

@misc{noauthor_home_nodate,
	title = {Home · dbpedia/extraction-framework {Wiki}},
	url = {https://github.com/dbpedia/extraction-framework},
	abstract = {The software used to extract structured data from Wikipedia - Home · dbpedia/extraction-framework Wiki},
	language = {en},
	urldate = {2022-10-18},
	journal = {GitHub},
	file = {Snapshot:C\:\\Users\\Anne\\Zotero\\storage\\M6Q2I6BT\\wiki.html:text/html},
}

@article{grimm_knowledge_nodate,
	title = {Knowledge {Representation} and {Ontologies}},
	abstract = {In Artiﬁcial Intelligence, knowledge representation studies the formalisation of knowledge and its processing within machines. Techniques of automated reasoning allow a computer system to draw conclusions from knowledge represented in a machine-interpretable form. Recently, ontologies have evolved in computer science as computational artefacts to provide computer systems with a conceptual yet computational model of a particular domain of interest. In this way, computer systems can base decisions on reasoning about domain knowledge, similar to humans. This chapter gives an overview on basic knowledge representation aspects and on ontologies as used within computer systems. After introducing ontologies in terms of their appearance, usage and classiﬁcation, it addresses concrete ontology languages that are particularly important in the context of the Semantic Web. The most recent and predominant ontology languages and formalisms are presented in relation to each other and a selection of them is discussed in more detail.},
	language = {en},
	author = {Grimm, Stephan and Hitzler, Pascal and Abecker, Andreas},
	pages = {51},
	file = {Grimm et al. - Knowledge Representation and Ontologies.pdf:C\:\\Users\\Anne\\Zotero\\storage\\WVL6R8BM\\Grimm et al. - Knowledge Representation and Ontologies.pdf:application/pdf},
}

@inproceedings{neumann_scispacy_2019,
	address = {Florence, Italy},
	title = {{ScispaCy}: {Fast} and {Robust} {Models} for {Biomedical} {Natural} {Language} {Processing}},
	shorttitle = {{ScispaCy}},
	url = {https://www.aclweb.org/anthology/W19-5034},
	doi = {10.18653/v1/W19-5034},
	abstract = {Despite recent advances in natural language processing, many statistical models for processing text perform extremely poorly under domain shift. Processing biomedical and clinical text is a critically important application area of natural language processing, for which there are few robust, practical, publicly available models. This paper describes scispaCy, a new Python library and models for practical biomedical/scientiﬁc text processing, which heavily leverages the spaCy library. We detail the performance of two packages of models released in scispaCy and demonstrate their robustness on several tasks and datasets. Models and code are available at https:// allenai.github.io/scispacy/.},
	language = {en},
	urldate = {2022-11-02},
	booktitle = {Proceedings of the 18th {BioNLP} {Workshop} and {Shared} {Task}},
	publisher = {Association for Computational Linguistics},
	author = {Neumann, Mark and King, Daniel and Beltagy, Iz and Ammar, Waleed},
	year = {2019},
	pages = {319--327},
	file = {Neumann et al. - 2019 - ScispaCy Fast and Robust Models for Biomedical Na.pdf:C\:\\Users\\Anne\\Zotero\\storage\\XD849G8U\\Neumann et al. - 2019 - ScispaCy Fast and Robust Models for Biomedical Na.pdf:application/pdf},
}

@misc{noauthor_readme_2022,
	title = {{READMe}},
	copyright = {CC-BY-4.0},
	url = {https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/df0df02fae6dbb87d88ffcf323b9096528f06f84/Additional%20file%201.pdf},
	urldate = {2022-11-02},
	publisher = {Cambridge Language Technology Lab},
	month = oct,
	year = {2022},
	note = {original-date: 2016-09-22T16:42:58Z},
}

@article{nunamaker_systems_1990-1,
	title = {Systems {Development} in {Information} {Systems} {Research}},
	volume = {7},
	issn = {0742-1222},
	url = {https://doi.org/10.1080/07421222.1990.11517898},
	doi = {10.1080/07421222.1990.11517898},
	abstract = {In this paper, the use of systems development as a methodology in information systems (is) research is described and defended. A framework to explain the nature of systems development as a research methodology in is research is proposed. Use of this methodology in the engineering field in general is compared with its use specifically in computer science and computer engineering. An integrated program for conducting is research that incorporates theory building, systems development, experimentation, and observation is proposed. Progress in several application domains is reviewed to provide a basis upon which to argue that systems development is a valid research methodology. A systems development research process is presented from a methodological perspective. Software engineering, which is the basic method of applying the systems development research methodology, is then discussed. It is the authors’ belief that systems development and other research methodologies are complementary and that an integrated multi-dimensional and multimethodological approach will generate fruitful is research results. The premise is that research contributions can result from systems development, experimentation, observation, and performance testing of the systems under development and that all of these research approaches are needed to investigate different aspects of the research question.},
	number = {3},
	urldate = {2022-11-02},
	journal = {Journal of Management Information Systems},
	author = {Nunamaker, Jay F. and Chen, Minder and Purdin, Titus D.M.},
	month = dec,
	year = {1990},
	note = {Publisher: Routledge
\_eprint: https://doi.org/10.1080/07421222.1990.11517898},
	pages = {89--106},
	file = {INFORMATIONS SYSTEMS DEVELOPMENT METHODLGY TQNQS.pdf:C\:\\Users\\Anne\\Zotero\\storage\\U97KZ62T\\INFORMATIONS SYSTEMS DEVELOPMENT METHODLGY TQNQS.pdf:application/pdf},
}
