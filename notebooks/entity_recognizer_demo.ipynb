{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of Entity Recognizer\n",
    "\n",
    "import warnings\n",
    "import random\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRecognizer\n",
    "from spacy.training import Example\n",
    "import xml.etree.ElementTree as ElementTree\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "nlp.remove_pipe('ner')      # remove standard NER ...\n",
    "ner = nlp.add_pipe(\"ner\")   # ... and create new NER \n",
    "\n",
    "pipe_exceptions = ['ner']   # Disable all pipeline components except NER before training the NER\n",
    "not_required_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "nlp.disable_pipes(*not_required_pipes)\n",
    "\n",
    "nlp.pipe_names              # Should now output only ['ner']\n",
    "\n",
    "# Load XML-file with training data\n",
    "\n",
    "entity_linker_export = ElementTree.parse(\"D:/Git_Fachpraktikum/MedExtractor/resources/all_entity_linker_export.xml\")\n",
    "root = entity_linker_export.getroot()\n",
    "\n",
    "# Prepare set of training samples\n",
    "\n",
    "TRAIN_DATA = []\n",
    "\n",
    "for sample in [item for item in root.iter(\"sample\")]:\n",
    "    \n",
    "    links_node = sample.find(\"links\")\n",
    "    \n",
    "    symptoms = []\n",
    "    for pos in links_node.iter(\"position\"):\n",
    "        \n",
    "        position = eval(pos.text)   # converts string like  \"(34,41)\" into tuple format\n",
    "        \n",
    "        symptoms.append((position[0],position[1],'SYMPTOM'))\n",
    "        \n",
    "    data = (sample.text,symptoms)\n",
    "    TRAIN_DATA.append(data)\n",
    "\n",
    "# Convert training samples into spacy.example objects    \n",
    "\n",
    "nlp.disable_pipes('ner')\n",
    "examples = []\n",
    "for i in range(25):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        example = Example.from_dict(nlp(text), {\"entities\": annotations})\n",
    "        examples.append(example)\n",
    "nlp.enable_pipe('ner')\n",
    "\n",
    "def give_examples():\n",
    "    return examples\n",
    "\n",
    "# Initialize and train the Entity Recognizer\n",
    "\n",
    "ner.initialize(give_examples)\n",
    "optimizer = nlp.create_optimizer()\n",
    "\n",
    "for example in give_examples():\n",
    "    nlp.update([example], sgd=optimizer)\n",
    "    \n",
    "nlp.enable_pipe('tok2vec')\n",
    "nlp.enable_pipe('tagger')\n",
    "nlp.enable_pipe('parser')\n",
    "nlp.enable_pipe('attribute_ruler')\n",
    "nlp.enable_pipe('lemmatizer')\n",
    "\n",
    "ner.to_disk(\"D:/Git_Fachpraktikum/MedExtractor/resources/ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of Entity Ruler\n",
    "\n",
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.training import Example\n",
    "import random\n",
    "import xml.etree.ElementTree as ElementTree\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "pipe_exceptions = ['tok2vec','tagger','parser','attribute_ruler','lemmatizer']\n",
    "not_required_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "nlp.disable_pipes(*not_required_pipes)\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "\n",
    "# Load XML-file with training data\n",
    "\n",
    "entity_linker_export = ElementTree.parse(\"D:/Git_Fachpraktikum/MedExtractor/resources/all_entity_linker_export.xml\")\n",
    "root = entity_linker_export.getroot()\n",
    "\n",
    "# Prepare set of training samples\n",
    "\n",
    "TRAIN_DATA = []\n",
    "\n",
    "for alias in [item for item in root.iter(\"alias\")]:\n",
    "    TRAIN_DATA.append({\"label\": \"SYMPTOM\", \"pattern\": alias.text})\n",
    "\n",
    "ruler.add_patterns(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057bb30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity Recognizer Test - No need to run 'Training of Entity Recognizer' script. Model is loaded from disk.\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.pipeline import EntityRecognizer\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "print(nlp.pipe_names)\n",
    "if nlp.has_pipe('entity_ruler'):\n",
    "    nlp.disable_pipes(['entity_ruler'])  # ensure that not the entity ruler is used for finding named entities\n",
    "nlp.remove_pipe('ner')                   # remove standard NER ...\n",
    "ner = nlp.add_pipe('ner')                # ... and create new NER \n",
    "nlp.enable_pipe('ner')\n",
    "ner.from_disk(\"D:/Git_Fachpraktikum/MedExtractor/resources/ner\")  # load statistical model\n",
    "text_file = open('D:/Git_Fachpraktikum/MedExtractor/resources/to_analyze_wikipedia/wikipedia_agoraphobia.txt','r',encoding=\"utf8\")\n",
    "text = text_file.read()\n",
    "p = re.compile('\\[\\d*?\\]')  # Remove literatur references such as '[23]'\n",
    "doc = nlp(p.sub('',text))\n",
    "text_file.close()\n",
    "displacy.render(doc,style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a631bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity Ruler Test - Please run 'Training of Entity Ruler' script first\n",
    "import re\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "nlp.disable_pipes(['ner'])  # ensure that not the entity recognizer is used for finding named entities\n",
    "nlp.enable_pipe('entity_ruler')\n",
    "print(nlp.pipe_names)\n",
    "text_file = open('D:/Git_Fachpraktikum/MedExtractor/resources/to_analyze_wikipedia/wikipedia_agoraphobia.txt','r',encoding=\"utf8\")\n",
    "text = text_file.read()\n",
    "p = re.compile('\\[\\d*?\\]')  # Remove literatur references such as '[23]'\n",
    "doc = nlp(p.sub('',text))\n",
    "displacy.render(doc,style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16237ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
