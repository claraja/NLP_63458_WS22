{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "507d27b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'entity_ruler']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy.training import Example\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "pipe_exceptions = ['tok2vec', 'tagger', 'parser']\n",
    "not_required_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "nlp.disable_pipes(*not_required_pipes)\n",
    "entity_ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06f2b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laden der XML-Datei\n",
    "\n",
    "import xml.etree.ElementTree as ElementTree\n",
    "\n",
    "entity_linker_export = ElementTree.parse(\"D:/Git_Fachpraktikum/MedExtractor/resources/med_entity_linker_export.xml\")\n",
    "root = entity_linker_export.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93770e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of Entity_Ruler\n",
    "\n",
    "train_data_ruler = []\n",
    "\n",
    "for entity in [item.text for item in root.iter(\"entity\")]:\n",
    "    to_train = {\"label\": \"DISEASE\", \"pattern\": entity}\n",
    "    train_data_ruler.append(to_train)\n",
    "\n",
    "for alias in [item.text for item in root.iter(\"alias\")]:\n",
    "    to_train = {\"label\": \"SYMPTOM\", \"pattern\": alias}\n",
    "    train_data_ruler.append(to_train)\n",
    "      \n",
    "entity_ruler.add_patterns(train_data_ruler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c134ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity_linker': 1.0223745346069335}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training of Entity Linker\n",
    "\n",
    "import random\n",
    "import math\n",
    "from spacy.kb import KnowledgeBase\n",
    "\n",
    "vocab = nlp.vocab\n",
    "\n",
    "def create_kb(vocab):\n",
    "    kb = KnowledgeBase(vocab=vocab, entity_vector_length=300)\n",
    "\n",
    "    for entity in [item.text for item in root.iter(\"entity\")]:\n",
    "        vector = nlp.vocab.get_vector(entity)\n",
    "        kb.add_entity(entity = entity, freq = 50, entity_vector = vector)\n",
    "\n",
    "    for alias in [item for item in root.iter(\"alias\")]:\n",
    "        entities = [entity.text for entity in alias.find(\"alias_entities\")]\n",
    "        kb.add_alias(alias = alias.text, entities = entities,probabilities = [0.001*math.floor(1000/len(entities))]*len(entities))\n",
    "        \n",
    "    return kb\n",
    "\n",
    "TRAIN_DATA = []\n",
    "\n",
    "for sample in [item for item in root.iter(\"sample\")]:\n",
    "    sample_data = [sample.text]\n",
    "    \n",
    "    annotations = []\n",
    "    links = {}\n",
    "    aliases = []\n",
    "    \n",
    "    alias_type = sample.find(\"links/alias_type\").text\n",
    "    links_node = sample.find(\"links\")\n",
    "    \n",
    "    for pos in links_node.iter(\"position\"):\n",
    "        entities = {}\n",
    "        position = eval(pos.text)\n",
    "        aliases.append((position[0],position[1],alias_type))\n",
    "        entities_training = pos.find(\"entities_training\")\n",
    "\n",
    "        for entity in entities_training:\n",
    "            entities[entity.text] = float(entity.find(\"probability\").find(\"prob\").text)\n",
    "        links[position] = entities\n",
    "\n",
    "    sample_data.append(aliases)\n",
    "    sample_data.append(links)\n",
    "    TRAIN_DATA.append(sample_data)\n",
    "\n",
    "for i in range(20):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    examples = []\n",
    "    for text, annotations, links in TRAIN_DATA:\n",
    "        doc = nlp(text)\n",
    "        gold_dict = {\"entities\": annotations, \"links\": links}\n",
    "        examples.append(Example.from_dict(doc, gold_dict))\n",
    "\n",
    "def give_examples():\n",
    "    return examples\n",
    "\n",
    "entity_linker = nlp.add_pipe('entity_linker')\n",
    "entity_linker.set_kb(create_kb)\n",
    "optimizer = entity_linker.create_optimizer()\n",
    "entity_linker.initialize(give_examples)\n",
    "entity_linker.update(examples, sgd=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab7e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Yesterday I entered the shopping mall when out of a sudden I had a panic attack.'\n",
    "          'I was hyperventilating for a moment and felt hot and sweaty. '\n",
    "          'And I started to feel chest pain.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22387b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "panic attack SYMPTOM ['agoraphobia', 'dysphagia', 'panic disorder', 'shock', 'social anxiety disorder']\n",
      "hyperventilating SYMPTOM ['agoraphobia']\n",
      "hot and sweaty SYMPTOM ['agoraphobia']\n",
      "chest pain SYMPTOM ['agoraphobia']\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    candidates = entity_linker.kb.get_alias_candidates(ent.text)\n",
    "    print(ent,ent.label_,[cand.entity_ for cand in candidates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a4f86b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "panic attack SYMPTOM panic disorder\n",
      "hyperventilating SYMPTOM agoraphobia\n",
      "hot and sweaty SYMPTOM agoraphobia\n",
      "chest pain SYMPTOM agoraphobia\n"
     ]
    }
   ],
   "source": [
    "predicts = entity_linker.predict(doc)\n",
    "for i,ent in enumerate(doc.ents):\n",
    "    print(ent,ent.label_,predicts[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
